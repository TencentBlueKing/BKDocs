# 资源及环境要求

## 网络
因为下载的镜像较大，所以推荐公网带宽至少为 50Mbps。如果带宽过低，则拉取镜像会消耗更多时间，可能导致部署超时。

>**提示**
>
>当网络带宽不足时，推荐提前 [缓存 Docker 镜像](docker-registry-cache.md)。

1. 中控机（部署前文件下载，以及部署开始时下载 charts）：
   1. 需要能访问蓝鲸静态文件分发站点：`https://bkopen-1252002024.file.myqcloud.com`。
   2. 需要能访问蓝鲸 Helm repo：`https://hub.bktencent.com/`。
2. k8s 集群（部署期间需要联网下载容器镜像）：
   1. 需要能访问 Docker Hub： `https://docker.io` 等。
   2. 需要能访问蓝鲸 Docker registry： `https://hub.bktencent.com/`。

## 中控机

部署和维护蓝鲸需要一台运维机，我们称之为“中控机”。本文所有操作命令，默认都是在中控机安装目录下执行的。

建议你复用已有的运维机，或者复用 k8s 集群的其中一台 `master` 机器。

如果计划设立单独的中控机，配置只需要 2 核 2GB 内存 100GB 磁盘即可。

部署脚本已在如下发行版下测试：
* CentOS
  * 8.6
  * 7.9
* TencentOS Server （详见 腾讯云 [云服务器公共镜像列表](https://cloud.tencent.com/document/product/213/93093)）
  * 3.1 （源码基于 CentOS 8）


## k8s 集群
### 硬件规格
>**注意**
>
>k8s 社区习惯以 `master` 和 `node` 称呼集群角色，本文沿用此习惯。但是 k8s 官网文档中已经将二者统称为 “node”（节点）。
>
>故除非另有说明，部署文档中的 `node` 一词默认不包含 `master`。当指代二者集合时，我们会使用 “全部 node” 来称呼。

如果你选择自建 k8s 集群，则需根据集群角色准备适当硬件规格的机器（物理机或虚拟机均可）：
* `master`，也称为 “master node” 或者 “control plane”。默认负责 k8s 集群本身的管理调度，配置要求较低（4 核心 8GB 内存 100GB 磁盘）。如果计划复用此节点承载业务，请和 node 配置对齐或者更高。
* `node` 负责承载业务运行。每台机器配置至少为 8 核心 32GB 内存。存储要求随负载而变，一般而言建议 node 具备 100GB 的可用空间，具体请查阅资源评估表。

>注意： 蓝盾公共构建机所有构建容器的规格统一。因此对于 CPU 及 磁盘存在要求的构建任务建议配置项目专属构建机。

### 资源评估表
如果你的硬件配置和“集群角色”章节中 “**基准配置（8 核心 32 GB 内存）**” 规格不同，请自行折算。

请按所需部署的套餐来决定集群规模：
|蓝鲸套餐 | 描述 | 最低配置 | 推荐配置 | 备注 |
| -- | -- | -- | -- | -- |
|基础套餐 | 后台及 SaaS | 3.5 台 node | 4 台 node | |
|容器管理平台 | 容器管理后台及 SaaS | 0.7 台 node | 1 台 node | |
|监控套餐 | 监控、日志服务及其 SaaS | 1.5 台 node | 2 台 node | 如启用容器监控，k8s 集群存储应大于 500G |
|持续集成套餐 | 流水线、代码检查 | 2 台 node | 2~5 台 node | 流水线任务较多时需扩容 node。如需私有构建机资源另计。 |

请按业务负载和存储类型决定磁盘容量和 IO 性能：
| 负载 | 存储类为本地存储 | 存储类为网络存储 | 备注 |
| -- | -- | -- | -- |
| 蓝鲸内置存储服务（blueking 命名空间下的 bk-mysql 等存储服务实例） | node 单 pv 可用空间至少 `50GB`，总容量 150GB；每个 node 磁盘 IO 性能至少为 `100op/s`。 | 对 node 要求较低。存储服务端 IOPS 配额至少为 `400op/s`，容量配额 150GB。 | 禁用部分内置服务，则对 k8s 存储要求降低。 |
| 蓝鲸制品库（用于作业平台、PaaS、节点管理使用、运维开发平台等）| bk-repo 所在 pv 可用空间至少 `90GB`，总容量 100GB。 | 服务端容量配额增加 100GB。 | |
| 基础主机监控（bk-influxdb） | bk-infuxdb 所在 pv 需要及时扩容。 | 服务端容量配额可增加 10GB。 | 容量视主机数量而定。 |
| 容器监控（bk-influxdb） | bk-infuxdb 所在 pv 需要及时扩容。 | 服务端容量配额增加 50GB。 | 容量随 k8s 规模而定。 |
| APM | bk-infuxdb、bk-elastic 所在 pv 需要及时扩容。 | 服务端容量配额增加 20GB。 | 容量随接入的应用数量及上报频率而定。 |
| 日志采集（bk-elastic） | bk-elastic 所在 pv 需要及时扩容 100GB 起。 | 服务端容量配额增加 100GB。 | 视日志文件而定，可能暴增，注意配置 ES 自动清理规则。 |
| 蓝盾流水线（公共构建机需要本地缓存空间） | 公共构建机所在 node `/data/landun` 目录需要确保可用空间大于 20GB。 | 不使用网络存储 | 如果未指定公共构建机，则 k8s 集群所有 node 都是公共构建机。 |
| 蓝鲸制品库对接蓝盾（流水线制品归档及报告、容器镜像存储、研发商店（构建镜像）） | bk-repo 所在 pv 扩容 300GB | 服务端容量配额增加 300GB。 | 流水线任务多制品较大时，可能导致容量暴增。 |


### 软件要求
| 需求项 | 具体要求 | 检查命令 |
| -- | -- | -- |
| 操作系统 | 建议 CentOS 8.6 / 7.9，64 位。部署文档中的脚本片段仅在 CentOS 系统下测试过，其他系统须自行调整。 | `cat /etc/centos-release` |
| kernel | 3.10.0 及以上 | `uname -r` |
| Swap | 关闭。防止 io 飙升影响 kubelet 进程。 | `free -m` Swap 这行值为 0 |
| 防火墙 | 关闭 | `iptables -vnL` 无其他规则 |
| SELinux | 关闭。k8s 官方要求。 | `getenforce` 的输出为 Disabled |
| 时区 | 所有服务器时区应该统一，建议使用北京时间 | 使用 `timedatectl set-timezone Asia/Shanghai` 设置为北京时间。 |
| 时间同步 | etcd 选举时要求 node 间时间差小于 1s | 配置 `chronyd` 同步时间 |
| containerd 版本 | 1.6 及更高 | `crictl version` |
| kubenetes 版本 | 推荐 1.24 版本。也在 1.20、1.23、1.30 版本测试部署通过。 | `kubectl version` |


# 下一步

[准备中控机](prepare-bkctrl.md)
